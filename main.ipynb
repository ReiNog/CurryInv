{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Finance Playground\n",
    "\n",
    "### Notebook dedicated to play with the financial functions that will be useful to investment management projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CDI - Brazilian Interbank Deposit Rate - Using the functions that work with the CDI rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback_with_variables import activate_in_ipython_by_import\n",
    "import pandas as pd\n",
    "import bacen as bc\n",
    "import ir_calc as ir\n",
    "import cdi\n",
    "\n",
    "# Defite the full path where the csv file with the CDI historical values is stored\n",
    "db_cdi_file = 'D:\\Investiments\\Databases\\Indexes\\CDI.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Update the CDI database with the most recent data - this must be done once a day to keep the CDI database up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdi.update_cdi_db(db_cdi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we can play with the CDI rate</p>\n",
    "<p>First we load the CDI do a data frame</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cdi = cdi.load_cdi(db_cdi_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate the final amount of a deposit indexed to 100% of the CDI<br>\n",
    "Note that when the percentage = 100%, it is not necessary to inform it to the function cdi.cdi_accum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_amount = 100000.00\n",
    "issue_date = pd.to_datetime('20220103')\n",
    "maturity_date = pd.to_datetime('20220801')\n",
    "\n",
    "maturity_amount = initial_amount * cdi.cdi_accum(df_cdi, issue_date, maturity_date)\n",
    "\n",
    "print(f'Final amount = ${maturity_amount:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets find the final amount of a deposit indexed to 90% of the CDI<br>\n",
    "We need to inform the percentage to the function cdi.cdi_accum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_amount = 100000.00\n",
    "percentage = 0.9\n",
    "issue_date = pd.to_datetime('20220103')\n",
    "maturity_date = pd.to_datetime('20220801')\n",
    "\n",
    "maturity_amount = initial_amount * cdi.cdi_accum(df_cdi, issue_date, maturity_date, percentage)\n",
    "\n",
    "print(f'Final amount = ${maturity_amount:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Selic - Brazilian monetary policy interest rate - Using the functions that work with the Selic rate\n",
    "\n",
    "##### Selic rate works the same way as the CDI rate, both are expressed as a percentage per annum, based on a two hundred fifty-two (252) business days year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback_with_variables import activate_in_ipython_by_import\n",
    "import pandas as pd\n",
    "import bacen as bc\n",
    "import ir_calc as ir\n",
    "import selic\n",
    "\n",
    "# Defite the full path where the csv file with the CDI historical values is stored\n",
    "db_selic_file = 'D:\\Investiments\\Databases\\Indexes\\Selic.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Update the Selic database with the most recent data - this must be done onde a day to keep the CDI database up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selic.update_selic_db(db_selic_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we can play with the Selic rate</p>\n",
    "<p>First we load the Selic do a data frame</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic = selic.load_selic(db_selic_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate the final amount of a deposit indexed to 100% of the Selic<br>\n",
    "Note that when the percentage = 100%, it is not necessary to inform it to the function selic.selic_accum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_amount = 100000.00\n",
    "issue_date = pd.to_datetime('20220103')\n",
    "maturity_date = pd.to_datetime('20220801')\n",
    "\n",
    "maturity_amount = initial_amount * selic.selic_accum(df_selic, issue_date, maturity_date)\n",
    "\n",
    "print(f'Final amount = ${maturity_amount:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets find the final amount of a deposit indexed to 90% of the Selic<br>\n",
    "We need to inform the percentage to the function selic.selic_accum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_amount = 100000.00\n",
    "percentage = 0.9\n",
    "issue_date = pd.to_datetime('20220103')\n",
    "maturity_date = pd.to_datetime('20220801')\n",
    "\n",
    "maturity_amount = initial_amount * selic.selic_accum(df_selic, issue_date, maturity_date, percentage)\n",
    "\n",
    "print(f'Final amount = ${maturity_amount:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Holydays and business days\n",
    "\n",
    "##### Some functions to find next business day, calculate number of business days between two dates, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import br_workdays as brbd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the number of business days between two dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "date1 = pd.to_datetime('2022-04-03')\n",
    "date2 = pd.to_datetime('2022-05-03')\n",
    "\n",
    "num_bdays = brbd.num_br_bdays(date1, date2)\n",
    "print(num_bdays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the next business day - the default number of business days to add is 1, thus it is not necessary to pass 1 to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date3 = brbd.next_br_bday(date1)\n",
    "print (date3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the date that is n bussines days forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "date3 = brbd.next_br_bday(date1,n)\n",
    "print (date3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the previous business day - the default number of business days to subtract is 1, thus it is not necessary to pass 1 to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date3 = brbd.prev_br_bday(date1)\n",
    "print (date3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the date that is n bussines days backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = -3\n",
    "date3 = brbd.prev_br_bday(date1,n)\n",
    "print (date3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking if a date is a business day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = pd.to_datetime('2022-09-06')  # True - it is a business day\n",
    "is_bday = brbd.is_br_bday(date1)   \n",
    "if is_bday:\n",
    "    print('{date1} is a business day in Brazil'.format(date1=date1.strftime('%d/%m/%Y')))\n",
    "else:\n",
    "    print('{date1} is not a business day in Brazil'.format(date1=date1.strftime('%d/%m/%Y')))\n",
    "    next_bday = brbd.next_br_bday(date1)\n",
    "    print('The first business day after {date1} is {date2}'.format(date1=date1.strftime('%d/%m/%Y'), date2=next_bday.strftime('%d/%m/%Y')))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = pd.to_datetime('2022-07-30') # False - it is a Saturday\n",
    "is_bday = brbd.is_br_bday(date1)   \n",
    "if is_bday:\n",
    "    print('{date1} is a business day in Brazil'.format(date1=date1.strftime('%d/%m/%Y')))\n",
    "else:\n",
    "    print('{date1} is not a business day in Brazil'.format(date1=date1.strftime('%d/%m/%Y')))\n",
    "    next_bday = brbd.next_br_bday(date1)\n",
    "    print('The first business day after {date1} is {date2}'.format(date1=date1.strftime('%d/%m/%Y'), date2=next_bday.strftime('%d/%m/%Y')))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = pd.to_datetime('2022-09-07')   # False - it is Brazil's Independence Day\n",
    "is_bday = brbd.is_br_bday(date1)   \n",
    "if is_bday:\n",
    "    print('{date1} is a business day in Brazil'.format(date1=date1.strftime('%d/%m/%Y')))\n",
    "else:\n",
    "    print('{date1} is not a business day in Brazil'.format(date1=date1.strftime('%d/%m/%Y')))\n",
    "    next_bday = brbd.next_br_bday(date1)\n",
    "    print('The first business day after {date1} is {date2}'.format(date1=date1.strftime('%d/%m/%Y'), date2=next_bday.strftime('%d/%m/%Y')))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/03/2020 is not a business day in Brazil\n",
      "The first business day after 01/03/2020 is 02/03/2020\n"
     ]
    }
   ],
   "source": [
    "date1 = pd.to_datetime('2020-03-02') \n",
    "is_bday = brbd.is_br_bday(date1)   \n",
    "if is_bday:\n",
    "    print('{date1} is a business day in Brazil'.format(date1=date1.strftime('%d/%m/%Y')))\n",
    "else:\n",
    "    print('{date1} is not a business day in Brazil'.format(date1=date1.strftime('%d/%m/%Y')))\n",
    "    next_bday = brbd.next_br_bday(date1)\n",
    "    print('The first business day after {date1} is {date2}'.format(date1=date1.strftime('%d/%m/%Y'), date2=next_bday.strftime('%d/%m/%Y')))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-exaustive unit tests of the num_br_bdays function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors = 0\n"
     ]
    }
   ],
   "source": [
    "test_dates = pd.DataFrame({'st_date':['20200201','20200101','20200203','20200203','20200203','20200203','20200203','20200203','20200217','20200217','20200217','20200217','20200217','20220401','20220501','20220403','20220501','20220415','20220501','20220416','20220510','20220425','20220501','20220416','20220410','20220425','20220403'], \n",
    "                        'end_date': ['20200301','20200201','20200303','20200301','20200215','20200216','20200210','20200225','20200301','20200316','20200310','20200225','20200303','20220501','20220601','20220503','20220503','20220503','20220516','20220516','20220516','20220516','20220503','20220503','20220503','20220503','20220503'], \n",
    "                        'num_bdays': [18,22,19,18,10,10,5,15,8,18,14,5,9,19,22,19,1,10,10,19,4,15,1,10,14,6,19]})\n",
    "test_dates['st_date'] = pd.to_datetime(test_dates['st_date'])\n",
    "test_dates['end_date'] = pd.to_datetime(test_dates['end_date'])\n",
    "error_count = 0\n",
    "\n",
    "for i in test_dates.index:\n",
    "    num_bdays = brbd.num_br_bdays(test_dates.loc[i]['st_date'], test_dates.loc[i]['end_date'])\n",
    "    if abs(num_bdays - test_dates.loc[i]['num_bdays']) > 0:\n",
    "        error_count += 1\n",
    "        print('Num bis days calculated differs from expected. Num bdays calculated: {bdays1}, Expected: {bdays2}'.format(bdays1=num_bdays, bdays2=test_dates.loc[i]['num_bdays']))\n",
    "\n",
    "print('Num errors = {nerr}'.format(nerr=error_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. IPCA - Brazilian official inflation index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipca\n",
    "import br_workdays as wd\n",
    "import ibge\n",
    "\n",
    "path_ipca = 'D:\\Investiments\\Databases\\Indexes\\IPCA.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading the IPCA rates from the IBGE API, updating the cumulative return and loading the IPCA database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ipca.update_ipca_db(path_ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ipca = ipca.load_ipca(path_ipca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating values indexed to IPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End amount = 39,517,688.59841448\n"
     ]
    }
   ],
   "source": [
    "date1 = pd.to_datetime('20220422')\n",
    "date2 = pd.to_datetime('20220601')\n",
    "ini_amount = 39208600.79\n",
    "end_amount = ini_amount * ipca.ipca_accum(df_ipca, date1, date2, 0, 'cd')\n",
    "print('End amount = {:,.2f}'.format(end_amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-exaustive unit tests of the ipca_accum function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors = 0\n"
     ]
    }
   ],
   "source": [
    "# Non-exaustive unit tests for the ipca_accum function - using calendar days for the pro-rata\n",
    "\n",
    "test_values_cd = pd.DataFrame({'issue_date': ['20200203','20200203','20200203','20200203','20200203','20200203','20200203','20200217','20200217','20200217','20200217','20200217'], \n",
    "                            'maturity_date': ['20220503','20220503','20220503','20220516','20220516','20220516','20220516','20220503','20220503','20220503','20220503','20220503'],\n",
    "                            'reset_day': [3,1,15,1,16,10,25,1,16,10,25,3],\n",
    "                            'f_accum': [1.19721652,1.19737254,1.19314617,1.19972932,1.19827020,1.19887131,1.19521345,1.19593011,1.19165612,1.19355504,1.18863815,1.19577427]})\n",
    "test_values_cd['issue_date'] = pd.to_datetime(test_values_cd['issue_date'])\n",
    "test_values_cd['maturity_date'] = pd.to_datetime(test_values_cd['maturity_date'])\n",
    "error_count = 0\n",
    "\n",
    "for x in test_values_cd.index:\n",
    "    f_accum_cd = ipca.ipca_accum(df_ipca, test_values_cd.loc[x]['issue_date'], test_values_cd.loc[x]['maturity_date'], test_values_cd.loc[x]['reset_day'], 'cd')\n",
    "    if abs(f_accum_cd - test_values_cd.loc[x]['f_accum']) > 0.00000002:\n",
    "        print('IPCA acummulated, calendar days, Start Date: {st_date}, End Date: {end_date}, Correct Accum = {ipca1:,.8f}, Calc Accum = {ipca2:,.8f}'.format(st_date=test_values_cd.loc[x]['issue_date'].strftime('%d/%m/%Y'),end_date=test_values_cd.loc[x]['maturity_date'].strftime('%d/%m/%Y'),ipca1=test_values_cd.loc[x]['f_accum'],ipca2=f_accum_cd))\n",
    "        error_count += 1\n",
    "\n",
    "print('Number of errors = {0}'.format(error_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors = 0\n"
     ]
    }
   ],
   "source": [
    "# Non-exaustive unit tests for the ipca_accum function - using business days for the pro-rata\n",
    "\n",
    "test_values_bd = pd.DataFrame({'issue_date': ['20200203','20200203','20200203','20200203','20200203','20200203','20200203','20200217','20200217','20200217','20200217','20200217'], \n",
    "                            'maturity_date': ['20220503','20220503','20220503','20220516','20220516','20220516','20220516','20220503','20220503','20220503','20220503','20220503'],\n",
    "                            'reset_day': [3,1,15,1,16,10,25,1,16,10,25,3],\n",
    "                            'f_accum': [1.19738260,1.19747171,1.19238823,1.19977094,1.19835866,1.19880905,1.19627167,1.19581179,1.19125177,1.19323683,1.18917716,1.19572280]})\n",
    "test_values_bd['issue_date'] = pd.to_datetime(test_values_bd['issue_date'])\n",
    "test_values_bd['maturity_date'] = pd.to_datetime(test_values_bd['maturity_date'])\n",
    "error_count = 0\n",
    "\n",
    "for x in test_values_bd.index:\n",
    "    f_accum_bd = ipca.ipca_accum(df_ipca, test_values_bd.loc[x]['issue_date'], test_values_bd.loc[x]['maturity_date'], test_values_bd.loc[x]['reset_day'], 'bd')\n",
    "    if abs(f_accum_bd - test_values_bd.loc[x]['f_accum']) > 0.00000002:\n",
    "        print('IPCA acummulated, calendar days, Start Date: {st_date}, End Date: {end_date}, Correct Accum = {ipca1:,.8f}, Calc Accum = {ipca2:,.8f}'.format(st_date=test_values_bd.loc[x]['issue_date'].strftime('%d/%m/%Y'),end_date=test_values_bd.loc[x]['maturity_date'].strftime('%d/%m/%Y'),ipca1=test_values_bd.loc[x]['f_accum'],ipca2=f_accum_bd))\n",
    "        error_count += 1\n",
    "\n",
    "print('Number of errors = {0}'.format(error_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. BRL/USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback_with_variables import activate_in_ipython_by_import\n",
    "import pandas as pd\n",
    "import bacen as bc\n",
    "import br_workdays as wd\n",
    "import fxrates as fx\n",
    "\n",
    "db_path='D:\\Investiments\\Databases\\Indexes\\BRLUSD.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx.update_brlusd_db(db_path)\n",
    "df_brlusd = fx.load_brlusd(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brlusd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = pd.to_datetime('20220103')\n",
    "date2 = pd.to_datetime('20220803')\n",
    "ini_amount = 1000000.00\n",
    "end_amount = ini_amount * fx.brlusd_accum(df_brlusd, date1, date2)\n",
    "print('End amount = {:,}'.format(end_amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping Unnamed columns\n",
    "# df_ = df_.loc[:,~df_.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Changing the name of a column\n",
    "# df_.rename(columns={'Fund':'Asset'}, inplace=True)\n",
    "\n",
    "# Reading a csv file\n",
    "# df_trades_funds = pd.read_csv(db_path, delimiter=';', dtype={'Client': int, 'Book': str}, index_col='TradeDate')\n",
    "\n",
    "# Writing a csv file\n",
    "# df_.to_csv(db_path, sep=';',header=['Rate','Accum'], index_label='TradeDate')\n",
    "# trades_funds.to_csv(db_path, sep=';',header=['Client', 'Book', 'Strategy', 'Asset', 'BuySell', 'Quantity', 'Price', 'Fees', 'Taxes', 'GrossAmount', 'NetAmount', 'NetPrice', 'SettlDate', 'BuyDate'], index_label='TradeDate')\n",
    "\n",
    "# Drop RiskClass, AssetClass and Currency from Trades' files - those classifications will be in the Asset master registry\n",
    "#db_path = 'D:\\Investiments\\Databases\\Portfolios\\client-000001\\Trades-Funds.csv'\n",
    "#trades_funds = pd.read_csv(db_path, delimiter=';', dtype={'Client':int, 'Book':str, 'Strategy':str, 'RiskClass':str, 'AssetClass':str, 'Asset':str, 'Currency':str, 'BuySell':str, 'Quantity':float, 'Price':float, 'Fees':float, 'Taxes':float, \n",
    "#                                                            'GrossAmount':float, 'NetAmount':float, 'NetPrice':float, 'SettlDate':str, 'BuyDate':str}, index_col=['TradeDate'])\n",
    "#trades_funds.index = pd.to_datetime(trades_funds.index,format='%Y-%m-%d')\n",
    "#trades_funds['SettlDate'] = pd.to_datetime(trades_funds['SettlDate'],format='%Y-%m-%d')\n",
    "#trades_funds['BuyDate'] = pd.to_datetime(trades_funds['BuyDate'],format='%Y-%m-%d')\n",
    "#trades_funds.sort_index()\n",
    "#trades_funds.drop(['RiskClass', 'AssetClass', 'Currency'], axis=1, inplace=True)\n",
    "#trades_funds.to_csv(db_path, sep=';',header=['Client', 'Book', 'Strategy', 'Asset','BuySell', 'Quantity', 'Price', 'Fees', 'Taxes', 'GrossAmount', 'NetAmount', 'NetPrice', 'SettlDate', 'BuyDate'], index_label='TradeDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback_with_variables import activate_in_ipython_by_import\n",
    "import pandas as pd\n",
    "import br_workdays as wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 14)\n"
     ]
    }
   ],
   "source": [
    "# Uploads the trades of the period, group the trades by date, client, book, strategy and asset, assuring there is one trade per date, and calculates the pnl of eventual daytrades\n",
    "db_path = 'D:\\Investiments\\Databases\\Portfolios\\client-000001\\Trades-Funds.csv'\n",
    "\n",
    "trades_funds = pd.read_csv(db_path, delimiter=';', \n",
    "                           dtype={'Client': int, 'Book': str, 'Strategy': str, 'Asset': str, 'BuySell':str, 'Quantity':float, 'Price': float, 'Fees': float, 'Taxes':float, 'GrossAmount': float, 'NetAmount': float, 'NetPrice': float, 'SettlDate': str, 'BuyDate': str}, \n",
    "                           index_col=['TradeDate'])\n",
    "trades_funds.index = pd.to_datetime(trades_funds.index,format='%Y-%m-%d')\n",
    "trades_funds['SettlDate'] = pd.to_datetime(trades_funds['SettlDate'],format='%Y-%m-%d')\n",
    "trades_funds['BuyDate'] = pd.to_datetime(trades_funds['BuyDate'],format='%Y-%m-%d')\n",
    "# trades_funds['Realized_Pnl'] = 0.00\n",
    "trades_funds.sort_index()\n",
    "\n",
    "# Necessary to group the records to assure the index key is unique\n",
    "groupby_list = ['TradeDate','Client','Book','Strategy','Asset','SettlDate']\n",
    "columns_tosum = ['Quantity','Price','Fees','Taxes','GrossAmount','NetAmount']\n",
    "buys = trades_funds.loc[trades_funds['BuySell']=='B'].groupby(by=groupby_list,)[columns_tosum].sum()\n",
    "buys['Price'] = -buys['GrossAmount']/buys['Quantity']\n",
    "buys['NetPrice'] = -buys['NetAmount']/buys['Quantity']\n",
    "sells = trades_funds.loc[trades_funds['BuySell']=='S'].groupby(by=groupby_list,)[columns_tosum].sum()\n",
    "sells['Price'] = -sells['GrossAmount']/sells['Quantity']\n",
    "sells['NetPrice'] = -sells['NetAmount']/sells['Quantity']\n",
    "\n",
    "print(buys.shape, sells.shape)\n",
    "\n",
    "# Carve out the daytrades to calculate the respective PnL and adjust the quantity bought or sold, after processing the daytrade\n",
    "daytrades = pd.merge(buys, sells, how='inner', on=groupby_list, suffixes=('_buy','_sell'))\n",
    "daytrades['Realized_Pnl'] = 0.00\n",
    "buys.drop(labels=daytrades.index, axis=0, inplace=True)\n",
    "sells.drop(labels=daytrades.index, axis=0, inplace=True)\n",
    "\n",
    "# Add columns BuySell and Realized_Pnl to buys and sells\n",
    "buys['BuySell'] = 'B'\n",
    "buys['Realized_Pnl'] = 0.00\n",
    "sells['BuySell'] = 'S'\n",
    "sells['Realized_Pnl'] = 0.00\n",
    "\n",
    "# Select the subset where quantity bought >= the quantity sold, calculates the Realized_Pnl of the daytrades, adjusts the quantity and relative amounts bought and drops the sells (that will be = 0)\n",
    "# When Quantity_buy = Quantity_sell, all quantities and amounts end up = 0 and only the Realized Pnl can be != 0. We have to keep the respective row to store the Realized_Pnl\n",
    "\n",
    "buy_gt_sell = daytrades.loc[daytrades['Quantity_buy'] >= daytrades['Quantity_sell']]\n",
    "\n",
    "if not buy_gt_sell.empty:\n",
    "    buy_gt_sell['Realized_Pnl'] = round(buy_gt_sell['NetAmount_sell'] + (buy_gt_sell['Quantity_sell'] * buy_gt_sell['NetPrice_buy']), 2)\n",
    "    buy_gt_sell['Fees_buy'] = round(buy_gt_sell['Fees_buy'] * (1- (buy_gt_sell['Quantity_sell'] / buy_gt_sell['Quantity_buy'])), 2)\n",
    "    buy_gt_sell['Taxes_buy'] = round(buy_gt_sell['Taxes_buy'] * (1- (buy_gt_sell['Quantity_sell'] / buy_gt_sell['Quantity_buy'])), 2)\n",
    "    buy_gt_sell['Quantity_buy'] = round(buy_gt_sell['Quantity_buy'] + buy_gt_sell['Quantity_sell'], 8)\n",
    "    buy_gt_sell['GrossAmount_buy'] = round(buy_gt_sell['Quantity_buy'] * buy_gt_sell['Price_buy'], 2)\n",
    "    buy_gt_sell['NetAmount_buy'] = round(buy_gt_sell['Quantity_buy'] * buy_gt_sell['NetPrice_buy'], 2)\n",
    "\n",
    "buy_gt_sell.drop(['Quantity_sell','Price_sell','Fees_sell','Taxes_sell','GrossAmount_sell','NetAmount_sell','NetPrice_sell'],axis=1, inplace=True)\n",
    "buy_gt_sell.rename(columns={'Quantity_buy':'Quantity','Price_buy':'Price','Fees_buy':'Fees','Taxes_buy':'Taxes','GrossAmount_buy':'GrossAmount','NetAmount_buy':'NetAmount','NetPrice_buy':'NetPrice'}, inplace=True)\n",
    "buy_gt_sell['BuySell'] = 'B'\n",
    "\n",
    "# Select the subset where Quantity_sell > Quantity_buy, calculates the Realized_Pnl of the daytrades, adjusts the quantity and relative amounts sold and drops the the buys (that will be = 0)\n",
    "sell_gt_buy = daytrades.loc[daytrades['Quantity_buy'] < daytrades['Quantity_sell']]\n",
    "\n",
    "if not sell_gt_buy.empty:\n",
    "    sell_gt_buy['Realized_Pnl'] = round(sell_gt_buy['NetAmount_buy'] + (sell_gt_buy['Quantity_buy'] * sell_gt_buy['NetPrice_sell']), 2)\n",
    "    sell_gt_buy['Fees_sell'] = round(sell_gt_buy['Fees_sell'] * (1- (sell_gt_buy['Quantity_buy'] / sell_gt_buy['Quantity_sell'])), 2)\n",
    "    sell_gt_buy['Taxes_sell'] = round(sell_gt_buy['Taxes_sell'] * (1- (sell_gt_buy['Quantity_buy'] / sell_gt_buy['Quantity_sell'])), 2)\n",
    "    sell_gt_buy['Quantity_sell'] = round(sell_gt_buy['Quantity_sell'] + sell_gt_buy['Quantity_buy'], 8)\n",
    "    sell_gt_buy['GrossAmount_sell'] = round(sell_gt_buy['Quantity_sell'] * sell_gt_buy['Price_sell'], 2)\n",
    "    sell_gt_buy['NetAmount_sell'] = round(sell_gt_buy['Quantity_sell'] * sell_gt_buy['NetPrice_sell'], 2)\n",
    "\n",
    "sell_gt_buy.drop(['Quantity_buy','Price_buy','Fees_buy','Taxes_buy','GrossAmount_buy','NetAmount_buy','NetPrice_buy'],axis=1, inplace=True)\n",
    "sell_gt_buy.rename(columns={'Quantity_sell':'Quantity','Price_sell':'Price','Fees_sell':'Fees','Taxes_sell':'Taxes','GrossAmount_sell':'GrossAmount','NetAmount_sell':'NetAmount','NetPrice_sell':'NetPrice'}, inplace=True)\n",
    "sell_gt_buy['BuySell'] = 'S'\n",
    "\n",
    "# Join back buys and sells into the trades_funds dataframe\n",
    "buys.reset_index(level=['Client','Book','Strategy','Asset','SettlDate'],inplace=True)\n",
    "sells.reset_index(level=['Client','Book','Strategy','Asset','SettlDate'],inplace=True)\n",
    "buy_gt_sell.reset_index(level=['Client','Book','Strategy','Asset','SettlDate'],inplace=True)\n",
    "sell_gt_buy.reset_index(level=['Client','Book','Strategy','Asset','SettlDate'],inplace=True)\n",
    "trades_funds = pd.concat([buys, buy_gt_sell, sells, sell_gt_buy])\n",
    "trades_funds.sort_index(axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import br_workdays as wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = pd.DataFrame(columns=['Quantity','Price','Value','Cost_price','Cost','Open_PnL','Realized_Pnl'], index=['Ref_Date','Client','Book','Strategy','Asset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = wd.list_of_br_bdays(trades_funds.first_valid_index,trades_funds.last_valid_index)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([10, 20, 30, 40], columns=['numbers'], index=['a', 'b', 'c', 'd']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numbers\n",
       "b       20\n",
       "c       30"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback_with_variables import activate_in_ipython_by_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_values = pd.DataFrame(data=[])\n",
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "new_values2 = pd.DataFrame(data=[])\n",
    "new_values = pd.concat([new_values, new_values2], axis=1)\n",
    "print(new_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('Venv1': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "578b54580852c8f3f942ce9823d34fceda592a2ee81225501e430f36dd9de2ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
